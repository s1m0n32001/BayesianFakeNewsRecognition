{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news recognition using a Multinomial Naive Bayes Classifier\n",
    "\n",
    "### Course: Advanced Statistics for Physics Analysis\n",
    "### Students: Toso Simone, Feltrin Antonio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "library(tm)             #Text-mining package\n",
    "library(NLP) \n",
    "library(textstem)      #For lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A bit of theory\n",
    "\n",
    "Our aim is to *classify* some phrases, using a predetermined set of categories $\\mathcal{C}$ (e.g. `{Fake, Not Fake}`).\n",
    "\n",
    "To do so, we must learn a *classification function* $\\gamma: \\mathcal{X} \\to \\mathcal{C}$, where $\\mathcal{X}$ is the set of all possible input phrases. \n",
    "\n",
    "There are many possible algorithms for text classification in natural language processing. In this project we will focus on the *Multinomial Naive Bayes* classifier.\n",
    "\n",
    "### The MNB classifier\n",
    "Given a class $c$ and a *document* (i.e. phrase) $d$, we can imagine that the document was composed by randomly extracting words from the total set of tokens $\\mathcal{T} = \\{t_1, t_2, \\dots, t_m\\}$. This way, the probability of composing the observed document would be\n",
    "\n",
    "$P(d|c) = \\prod_{1 \\leq k \\leq n_d} p(t_k|c)$.\n",
    "\n",
    "Now, we want to infer $P(c|d)$. This can be done though Bayes's Theorem:\n",
    "\n",
    "$P(c|d) \\propto p(c) \\prod_{1 \\leq k \\leq n_d} p(t_k|c)$.\n",
    "\n",
    "We can then easily find the *maximum a posteriori* class $c_{map}$:\n",
    "\n",
    "$c_{map} = \\mathrm{argmax}_{c} P(d|c)$.\n",
    "\n",
    "The maximum a posteriori class will be our guess for the classification.\n",
    "\n",
    "### The learning algorithm\n",
    "Our model depends on the following parameters:\n",
    "* **Prior**: $p(c)$. \n",
    "* **Token probability**: $p(t_k|c)$, the probability for token $t_k$ to appear in a document of class $c$. \n",
    "\n",
    "The prior can be estimated as $\\hat{p}(c) = \\frac{N_c}{N}$, i.e. the fraction of documents of class $c$ in the training set.\n",
    "\n",
    "The token probability can instead be estimated as $\\hat{p}(t|c) = \\frac{T_{ct} + 1}{\\sum_{t'} (T_{ct' + 1})}$. The term $T_{ct}$ is the number of times token $t$ appears in a document of class $c$. Notice that, both at the numerator and denominator, we are adding $1$ to $T_{ct}$ and $T_{ct'}$. This is done in order to avoid having $p(t|c) = 0$ for tokens that never appear in documents of class $c$.\n",
    "\n",
    "<hr style=\"border:1px solid gray\">\n",
    "\n",
    "\n",
    "# Kumar dataset \n",
    "\n",
    "We first try our hand on [this](https://www.kaggle.com/datasets/anmolkumar/fake-news-content-detection?select=train.csv) dataset. It consists of 11507 records (10240 for training, 1267 for testing)\n",
    "\n",
    "Each entry is classified as one of these 6 categories:\n",
    "* *Barely true* - 0\n",
    "* *False* - 1\n",
    "* *Half-true* - 2\n",
    "* *Mostly true* - 3\n",
    "* *Not known* - 4\n",
    "* *True* - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dir_input <- 'data/kumar/train_pruned.csv'\n",
    "dir_test <- 'data/kumar/test.csv'\n",
    "input.df <- read.csv(dir_input,header=TRUE,sep=',')\n",
    "test.df <- read.csv(dir_test,header=TRUE,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Labels</th><th scope=col>Text</th><th scope=col>Text_Tag</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>Says the Annies List political group supports third-trimester abortions on demand.                                                                             </td><td>abortion                          </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.                  </td><td>energy,history,job-accomplishments</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                      </td><td>foreign-policy                    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>Health care reform legislation is likely to mandate free sex change surgeries.                                                                                 </td><td>health-care                       </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2</td><td>The economic turnaround started at the end of my term.                                                                                                         </td><td>economy,jobs                      </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5</td><td>The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.    </td><td>education                         </td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0</td><td>Jim Dunnam has not lived in the district he represents for years now.                                                                                          </td><td>candidates-biography              </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>2</td><td>I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate.</td><td>ethics                            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Labels & Text & Text\\_Tag\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & Says the Annies List political group supports third-trimester abortions on demand.                                                                              & abortion                          \\\\\n",
       "\t2 & 2 & When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.                   & energy,history,job-accomplishments\\\\\n",
       "\t3 & 3 & Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                       & foreign-policy                    \\\\\n",
       "\t4 & 1 & Health care reform legislation is likely to mandate free sex change surgeries.                                                                                  & health-care                       \\\\\n",
       "\t5 & 2 & The economic turnaround started at the end of my term.                                                                                                          & economy,jobs                      \\\\\n",
       "\t6 & 5 & The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.     & education                         \\\\\n",
       "\t7 & 0 & Jim Dunnam has not lived in the district he represents for years now.                                                                                           & candidates-biography              \\\\\n",
       "\t8 & 2 & I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate. & ethics                            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 3\n",
       "\n",
       "| <!--/--> | Labels &lt;int&gt; | Text &lt;chr&gt; | Text_Tag &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | Says the Annies List political group supports third-trimester abortions on demand.                                                                              | abortion                           |\n",
       "| 2 | 2 | When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.                   | energy,history,job-accomplishments |\n",
       "| 3 | 3 | Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                       | foreign-policy                     |\n",
       "| 4 | 1 | Health care reform legislation is likely to mandate free sex change surgeries.                                                                                  | health-care                        |\n",
       "| 5 | 2 | The economic turnaround started at the end of my term.                                                                                                          | economy,jobs                       |\n",
       "| 6 | 5 | The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.     | education                          |\n",
       "| 7 | 0 | Jim Dunnam has not lived in the district he represents for years now.                                                                                           | candidates-biography               |\n",
       "| 8 | 2 | I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate. | ethics                             |\n",
       "\n"
      ],
      "text/plain": [
       "  Labels\n",
       "1 1     \n",
       "2 2     \n",
       "3 3     \n",
       "4 1     \n",
       "5 2     \n",
       "6 5     \n",
       "7 0     \n",
       "8 2     \n",
       "  Text                                                                                                                                                           \n",
       "1 Says the Annies List political group supports third-trimester abortions on demand.                                                                             \n",
       "2 When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.                  \n",
       "3 Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"                                                      \n",
       "4 Health care reform legislation is likely to mandate free sex change surgeries.                                                                                 \n",
       "5 The economic turnaround started at the end of my term.                                                                                                         \n",
       "6 The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.    \n",
       "7 Jim Dunnam has not lived in the district he represents for years now.                                                                                          \n",
       "8 I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate.\n",
       "  Text_Tag                          \n",
       "1 abortion                          \n",
       "2 energy,history,job-accomplishments\n",
       "3 foreign-policy                    \n",
       "4 health-care                       \n",
       "5 economy,jobs                      \n",
       "6 education                         \n",
       "7 candidates-biography              \n",
       "8 ethics                            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(input.df,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary construction and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plain <- function(word,punct='[:punct:]'){\n",
    "    word <- str_to_lower(str_replace_all(word,punct,' '))\n",
    "    return(word) \n",
    "}\n",
    "\n",
    "get.unique.words <- function (tags.bag,sep,sortit=FALSE) {\n",
    "    all.tags <- c()\n",
    "    for (record in tags.bag){\n",
    "        temp.tags <- str_split_1(plain(record),sep)\n",
    "        for (word in temp.tags) {\n",
    "            word <- plain(word)\n",
    "            if (word %in% all.tags == FALSE & word != '') {\n",
    "                    all.tags <- c(all.tags,str_to_lower(word))\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    if (sortit) {all.tags <- sort(all.tags)}\n",
    "    return(all.tags)\n",
    "}\n",
    "\n",
    "get.quotes <- function (quotes.bag,sep) {\n",
    "    all.quotes <- list()\n",
    "    for (record in quotes.bag){\n",
    "        temp.q <- str_split_1(plain(record),sep)\n",
    "        temp.q <- str_flatten(temp.q[!(temp.q %in% stopwords('en')) & str_length(temp.q)>0], collapse = ' ') #>1 to remove lone letters? no because of $\n",
    "        all.quotes <- c(all.quotes,temp.q)\n",
    "        }\n",
    "\n",
    "    return(all.quotes)\n",
    "}\n",
    "\n",
    "get.tags <- function (tags.bag,sep) {\n",
    "    all.quotes <- list()\n",
    "    for (record in tags.bag){\n",
    "        #cat('\\nrecord, type',record,typeof(record))\n",
    "        temp.q <- str_split(plain(record,punct = '[.;()]'),sep)\n",
    "        temp.q <- str_flatten(temp.q[[1]][!(temp.q %in% stopwords('en'))],  collapse = ' ') #>1 to remove lone letters? no because of $\n",
    "        all.quotes <- c(all.quotes,temp.q)\n",
    "        }\n",
    "\n",
    "    return(all.quotes)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "input.tags <- get.unique.words(input.df$Text_Tag,sep=',',sortit=TRUE)\n",
    "test.tags <- get.unique.words(test.df$Text_Tag,sep=',',sortit=TRUE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "quotes <- get.quotes(input.df$Text,sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tags <- get.tags(input.df$Text_Tag,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train.df <- data.frame(Labels = input.df$Labels, Text = unlist(quotes), Text_Tag = unlist(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 5 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Labels</th><th scope=col>Text</th><th scope=col>Text_Tag</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>says annies list political group supports third trimester abortions demand                       </td><td>abortion                          </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>decline coal start started natural gas took started begin president george w bushs administration</td><td>energy history job-accomplishments</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>hillary clinton agrees john mccain voting give george bush benefit doubt iran                    </td><td>foreign-policy                    </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>health care reform legislation likely mandate free sex change surgeries                          </td><td>health-care                       </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2</td><td>economic turnaround started end term                                                             </td><td>economy jobs                      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 5 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Labels & Text & Text\\_Tag\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & says annies list political group supports third trimester abortions demand                        & abortion                          \\\\\n",
       "\t2 & 2 & decline coal start started natural gas took started begin president george w bushs administration & energy history job-accomplishments\\\\\n",
       "\t3 & 3 & hillary clinton agrees john mccain voting give george bush benefit doubt iran                     & foreign-policy                    \\\\\n",
       "\t4 & 1 & health care reform legislation likely mandate free sex change surgeries                           & health-care                       \\\\\n",
       "\t5 & 2 & economic turnaround started end term                                                              & economy jobs                      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 5 × 3\n",
       "\n",
       "| <!--/--> | Labels &lt;int&gt; | Text &lt;chr&gt; | Text_Tag &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | says annies list political group supports third trimester abortions demand                        | abortion                           |\n",
       "| 2 | 2 | decline coal start started natural gas took started begin president george w bushs administration | energy history job-accomplishments |\n",
       "| 3 | 3 | hillary clinton agrees john mccain voting give george bush benefit doubt iran                     | foreign-policy                     |\n",
       "| 4 | 1 | health care reform legislation likely mandate free sex change surgeries                           | health-care                        |\n",
       "| 5 | 2 | economic turnaround started end term                                                              | economy jobs                       |\n",
       "\n"
      ],
      "text/plain": [
       "  Labels\n",
       "1 1     \n",
       "2 2     \n",
       "3 3     \n",
       "4 1     \n",
       "5 2     \n",
       "  Text                                                                                             \n",
       "1 says annies list political group supports third trimester abortions demand                       \n",
       "2 decline coal start started natural gas took started begin president george w bushs administration\n",
       "3 hillary clinton agrees john mccain voting give george bush benefit doubt iran                    \n",
       "4 health care reform legislation likely mandate free sex change surgeries                          \n",
       "5 economic turnaround started end term                                                             \n",
       "  Text_Tag                          \n",
       "1 abortion                          \n",
       "2 energy history job-accomplishments\n",
       "3 foreign-policy                    \n",
       "4 health-care                       \n",
       "5 economy jobs                      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train.df,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train.df$Text <- lemmatize_strings(train.df$Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Labels</th><th scope=col>Text</th><th scope=col>Text_Tag</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td><span style=white-space:pre-wrap>say annies list political group support &lt;NUMBER&gt; trimester abortion demand                                                     </span></td><td><span style=white-space:pre-wrap>abortion                                 </span></td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>decline coal start start natural gas take start begin president george w bushs administration                                  </td><td>energy history job-accomplishments       </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>hillary clinton agree john mccain vote give george bush benefit doubt iran                                                     </td><td>foreign-policy                           </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>health care reform legislation likely mandate free sex change surgery                                                          </td><td>health-care                              </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2</td><td>economic turnaround start end term                                                                                             </td><td>economy jobs                             </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5</td><td><span style=white-space:pre-wrap>chicago bear start quarterback last &lt;NUMBER&gt; year total numb tenure uw faculty fire last two decade                            </span></td><td><span style=white-space:pre-wrap>education                                </span></td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0</td><td>jim dunnam live district represent year now                                                                                    </td><td>candidates-biography                     </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>2</td><td>be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                       </td><td>ethics                                   </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>2</td><td>however take &lt;MONEY&gt; &lt;NUMBER&gt; million oregon lottery fund port newport eventually land new noaa marine operation center pacific</td><td><span style=white-space:pre-wrap>jobs                                     </span></td></tr>\n",
       "\t<tr><th scope=row>10</th><td>3</td><td><span style=white-space:pre-wrap>say gop primary opponent glenn grothman joe leibham cast compromise vote cost &lt;MONEY&gt; million high electricity cost            </span></td><td>energy message-machine-2014 voting-record</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>3</td><td>first time history share national popular vote margin small latino vote margin                                                 </td><td>elections                                </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>2</td><td><span style=white-space:pre-wrap>since &lt;YEAR&gt; nearly &lt;NUMBER&gt; million american slip middle class poverty                                                        </span></td><td><span style=white-space:pre-wrap>economy jobs new-hampshire-2012 poverty  </span></td></tr>\n",
       "\t<tr><th scope=row>13</th><td>1</td><td>mitt romney governor massachusetts didnt just slow rate growth government actually cut                                         </td><td>history state-budget                     </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>3</td><td><span style=white-space:pre-wrap>economy bleed &lt;MONEY&gt; billion due government shutdown                                                                          </span></td><td><span style=white-space:pre-wrap>economy federal-budget health-care       </span></td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0</td><td>affordable care act already sense waive otherwise suspend                                                                      </td><td>health-care                              </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Labels & Text & Text\\_Tag\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & say annies list political group support <NUMBER> trimester abortion demand                                                      & abortion                                 \\\\\n",
       "\t2 & 2 & decline coal start start natural gas take start begin president george w bushs administration                                   & energy history job-accomplishments       \\\\\n",
       "\t3 & 3 & hillary clinton agree john mccain vote give george bush benefit doubt iran                                                      & foreign-policy                           \\\\\n",
       "\t4 & 1 & health care reform legislation likely mandate free sex change surgery                                                           & health-care                              \\\\\n",
       "\t5 & 2 & economic turnaround start end term                                                                                              & economy jobs                             \\\\\n",
       "\t6 & 5 & chicago bear start quarterback last <NUMBER> year total numb tenure uw faculty fire last two decade                             & education                                \\\\\n",
       "\t7 & 0 & jim dunnam live district represent year now                                                                                     & candidates-biography                     \\\\\n",
       "\t8 & 2 & be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                        & ethics                                   \\\\\n",
       "\t9 & 2 & however take <MONEY> <NUMBER> million oregon lottery fund port newport eventually land new noaa marine operation center pacific & jobs                                     \\\\\n",
       "\t10 & 3 & say gop primary opponent glenn grothman joe leibham cast compromise vote cost <MONEY> million high electricity cost             & energy message-machine-2014 voting-record\\\\\n",
       "\t11 & 3 & first time history share national popular vote margin small latino vote margin                                                  & elections                                \\\\\n",
       "\t12 & 2 & since <YEAR> nearly <NUMBER> million american slip middle class poverty                                                         & economy jobs new-hampshire-2012 poverty  \\\\\n",
       "\t13 & 1 & mitt romney governor massachusetts didnt just slow rate growth government actually cut                                          & history state-budget                     \\\\\n",
       "\t14 & 3 & economy bleed <MONEY> billion due government shutdown                                                                           & economy federal-budget health-care       \\\\\n",
       "\t15 & 0 & affordable care act already sense waive otherwise suspend                                                                       & health-care                              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 3\n",
       "\n",
       "| <!--/--> | Labels &lt;int&gt; | Text &lt;chr&gt; | Text_Tag &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | say annies list political group support &lt;NUMBER&gt; trimester abortion demand                                                      | abortion                                  |\n",
       "| 2 | 2 | decline coal start start natural gas take start begin president george w bushs administration                                   | energy history job-accomplishments        |\n",
       "| 3 | 3 | hillary clinton agree john mccain vote give george bush benefit doubt iran                                                      | foreign-policy                            |\n",
       "| 4 | 1 | health care reform legislation likely mandate free sex change surgery                                                           | health-care                               |\n",
       "| 5 | 2 | economic turnaround start end term                                                                                              | economy jobs                              |\n",
       "| 6 | 5 | chicago bear start quarterback last &lt;NUMBER&gt; year total numb tenure uw faculty fire last two decade                             | education                                 |\n",
       "| 7 | 0 | jim dunnam live district represent year now                                                                                     | candidates-biography                      |\n",
       "| 8 | 2 | be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                        | ethics                                    |\n",
       "| 9 | 2 | however take &lt;MONEY&gt; &lt;NUMBER&gt; million oregon lottery fund port newport eventually land new noaa marine operation center pacific | jobs                                      |\n",
       "| 10 | 3 | say gop primary opponent glenn grothman joe leibham cast compromise vote cost &lt;MONEY&gt; million high electricity cost             | energy message-machine-2014 voting-record |\n",
       "| 11 | 3 | first time history share national popular vote margin small latino vote margin                                                  | elections                                 |\n",
       "| 12 | 2 | since &lt;YEAR&gt; nearly &lt;NUMBER&gt; million american slip middle class poverty                                                         | economy jobs new-hampshire-2012 poverty   |\n",
       "| 13 | 1 | mitt romney governor massachusetts didnt just slow rate growth government actually cut                                          | history state-budget                      |\n",
       "| 14 | 3 | economy bleed &lt;MONEY&gt; billion due government shutdown                                                                           | economy federal-budget health-care        |\n",
       "| 15 | 0 | affordable care act already sense waive otherwise suspend                                                                       | health-care                               |\n",
       "\n"
      ],
      "text/plain": [
       "   Labels\n",
       "1  1     \n",
       "2  2     \n",
       "3  3     \n",
       "4  1     \n",
       "5  2     \n",
       "6  5     \n",
       "7  0     \n",
       "8  2     \n",
       "9  2     \n",
       "10 3     \n",
       "11 3     \n",
       "12 2     \n",
       "13 1     \n",
       "14 3     \n",
       "15 0     \n",
       "   Text                                                                                                                           \n",
       "1  say annies list political group support <NUMBER> trimester abortion demand                                                     \n",
       "2  decline coal start start natural gas take start begin president george w bushs administration                                  \n",
       "3  hillary clinton agree john mccain vote give george bush benefit doubt iran                                                     \n",
       "4  health care reform legislation likely mandate free sex change surgery                                                          \n",
       "5  economic turnaround start end term                                                                                             \n",
       "6  chicago bear start quarterback last <NUMBER> year total numb tenure uw faculty fire last two decade                            \n",
       "7  jim dunnam live district represent year now                                                                                    \n",
       "8  be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                       \n",
       "9  however take <MONEY> <NUMBER> million oregon lottery fund port newport eventually land new noaa marine operation center pacific\n",
       "10 say gop primary opponent glenn grothman joe leibham cast compromise vote cost <MONEY> million high electricity cost            \n",
       "11 first time history share national popular vote margin small latino vote margin                                                 \n",
       "12 since <YEAR> nearly <NUMBER> million american slip middle class poverty                                                        \n",
       "13 mitt romney governor massachusetts didnt just slow rate growth government actually cut                                         \n",
       "14 economy bleed <MONEY> billion due government shutdown                                                                          \n",
       "15 affordable care act already sense waive otherwise suspend                                                                      \n",
       "   Text_Tag                                 \n",
       "1  abortion                                 \n",
       "2  energy history job-accomplishments       \n",
       "3  foreign-policy                           \n",
       "4  health-care                              \n",
       "5  economy jobs                             \n",
       "6  education                                \n",
       "7  candidates-biography                     \n",
       "8  ethics                                   \n",
       "9  jobs                                     \n",
       "10 energy message-machine-2014 voting-record\n",
       "11 elections                                \n",
       "12 economy jobs new-hampshire-2012 poverty  \n",
       "13 history state-budget                     \n",
       "14 economy federal-budget health-care       \n",
       "15 health-care                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train.df,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APPLY FILTERS: \n",
    "\n",
    "#### FILTER1 regexp '$NUM' -> somemoney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df$Text <- str_replace_all(train.df$Text, regex(\"\\\\$[0-9]*\"), \"<MONEY>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTER2 regexp '19xx' or '20xx' -> someyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'since 2000 nearly 12 million american slip middle class poverty'"
      ],
      "text/latex": [
       "'since 2000 nearly 12 million american slip middle class poverty'"
      ],
      "text/markdown": [
       "'since 2000 nearly 12 million american slip middle class poverty'"
      ],
      "text/plain": [
       "[1] \"since 2000 nearly 12 million american slip middle class poverty\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.df$Text[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df$Text <- str_replace_all(train.df$Text, regex(\"(18|19|20)\\\\d{2}\"), \"<YEAR>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FILTER 3 numero --> \"< number >\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.df$Text <- str_replace_all(train.df$Text, regex(\"\\\\d+\"), \"<NUMBER>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "#### Let's see how our dataset is now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 15 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Labels</th><th scope=col>Text</th><th scope=col>Text_Tag</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td><span style=white-space:pre-wrap>say annies list political group support &lt;NUMBER&gt; trimester abortion demand                                                     </span></td><td><span style=white-space:pre-wrap>abortion                                 </span></td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>decline coal start start natural gas take start begin president george w bushs administration                                  </td><td>energy history job-accomplishments       </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td>hillary clinton agree john mccain vote give george bush benefit doubt iran                                                     </td><td>foreign-policy                           </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1</td><td>health care reform legislation likely mandate free sex change surgery                                                          </td><td>health-care                              </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>2</td><td>economic turnaround start end term                                                                                             </td><td>economy jobs                             </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>5</td><td><span style=white-space:pre-wrap>chicago bear start quarterback last &lt;NUMBER&gt; year total numb tenure uw faculty fire last two decade                            </span></td><td><span style=white-space:pre-wrap>education                                </span></td></tr>\n",
       "\t<tr><th scope=row>7</th><td>0</td><td>jim dunnam live district represent year now                                                                                    </td><td>candidates-biography                     </td></tr>\n",
       "\t<tr><th scope=row>8</th><td>2</td><td>be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                       </td><td>ethics                                   </td></tr>\n",
       "\t<tr><th scope=row>9</th><td>2</td><td>however take &lt;MONEY&gt; &lt;NUMBER&gt; million oregon lottery fund port newport eventually land new noaa marine operation center pacific</td><td><span style=white-space:pre-wrap>jobs                                     </span></td></tr>\n",
       "\t<tr><th scope=row>10</th><td>3</td><td><span style=white-space:pre-wrap>say gop primary opponent glenn grothman joe leibham cast compromise vote cost &lt;MONEY&gt; million high electricity cost            </span></td><td>energy message-machine-2014 voting-record</td></tr>\n",
       "\t<tr><th scope=row>11</th><td>3</td><td>first time history share national popular vote margin small latino vote margin                                                 </td><td>elections                                </td></tr>\n",
       "\t<tr><th scope=row>12</th><td>2</td><td><span style=white-space:pre-wrap>since &lt;YEAR&gt; nearly &lt;NUMBER&gt; million american slip middle class poverty                                                        </span></td><td><span style=white-space:pre-wrap>economy jobs new-hampshire-2012 poverty  </span></td></tr>\n",
       "\t<tr><th scope=row>13</th><td>1</td><td>mitt romney governor massachusetts didnt just slow rate growth government actually cut                                         </td><td>history state-budget                     </td></tr>\n",
       "\t<tr><th scope=row>14</th><td>3</td><td><span style=white-space:pre-wrap>economy bleed &lt;MONEY&gt; billion due government shutdown                                                                          </span></td><td><span style=white-space:pre-wrap>economy federal-budget health-care       </span></td></tr>\n",
       "\t<tr><th scope=row>15</th><td>0</td><td>affordable care act already sense waive otherwise suspend                                                                      </td><td>health-care                              </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 15 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & Labels & Text & Text\\_Tag\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & say annies list political group support <NUMBER> trimester abortion demand                                                      & abortion                                 \\\\\n",
       "\t2 & 2 & decline coal start start natural gas take start begin president george w bushs administration                                   & energy history job-accomplishments       \\\\\n",
       "\t3 & 3 & hillary clinton agree john mccain vote give george bush benefit doubt iran                                                      & foreign-policy                           \\\\\n",
       "\t4 & 1 & health care reform legislation likely mandate free sex change surgery                                                           & health-care                              \\\\\n",
       "\t5 & 2 & economic turnaround start end term                                                                                              & economy jobs                             \\\\\n",
       "\t6 & 5 & chicago bear start quarterback last <NUMBER> year total numb tenure uw faculty fire last two decade                             & education                                \\\\\n",
       "\t7 & 0 & jim dunnam live district represent year now                                                                                     & candidates-biography                     \\\\\n",
       "\t8 & 2 & be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                        & ethics                                   \\\\\n",
       "\t9 & 2 & however take <MONEY> <NUMBER> million oregon lottery fund port newport eventually land new noaa marine operation center pacific & jobs                                     \\\\\n",
       "\t10 & 3 & say gop primary opponent glenn grothman joe leibham cast compromise vote cost <MONEY> million high electricity cost             & energy message-machine-2014 voting-record\\\\\n",
       "\t11 & 3 & first time history share national popular vote margin small latino vote margin                                                  & elections                                \\\\\n",
       "\t12 & 2 & since <YEAR> nearly <NUMBER> million american slip middle class poverty                                                         & economy jobs new-hampshire-2012 poverty  \\\\\n",
       "\t13 & 1 & mitt romney governor massachusetts didnt just slow rate growth government actually cut                                          & history state-budget                     \\\\\n",
       "\t14 & 3 & economy bleed <MONEY> billion due government shutdown                                                                           & economy federal-budget health-care       \\\\\n",
       "\t15 & 0 & affordable care act already sense waive otherwise suspend                                                                       & health-care                              \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 15 × 3\n",
       "\n",
       "| <!--/--> | Labels &lt;int&gt; | Text &lt;chr&gt; | Text_Tag &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | say annies list political group support &lt;NUMBER&gt; trimester abortion demand                                                      | abortion                                  |\n",
       "| 2 | 2 | decline coal start start natural gas take start begin president george w bushs administration                                   | energy history job-accomplishments        |\n",
       "| 3 | 3 | hillary clinton agree john mccain vote give george bush benefit doubt iran                                                      | foreign-policy                            |\n",
       "| 4 | 1 | health care reform legislation likely mandate free sex change surgery                                                           | health-care                               |\n",
       "| 5 | 2 | economic turnaround start end term                                                                                              | economy jobs                              |\n",
       "| 6 | 5 | chicago bear start quarterback last &lt;NUMBER&gt; year total numb tenure uw faculty fire last two decade                             | education                                 |\n",
       "| 7 | 0 | jim dunnam live district represent year now                                                                                     | candidates-biography                      |\n",
       "| 8 | 2 | be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                        | ethics                                    |\n",
       "| 9 | 2 | however take &lt;MONEY&gt; &lt;NUMBER&gt; million oregon lottery fund port newport eventually land new noaa marine operation center pacific | jobs                                      |\n",
       "| 10 | 3 | say gop primary opponent glenn grothman joe leibham cast compromise vote cost &lt;MONEY&gt; million high electricity cost             | energy message-machine-2014 voting-record |\n",
       "| 11 | 3 | first time history share national popular vote margin small latino vote margin                                                  | elections                                 |\n",
       "| 12 | 2 | since &lt;YEAR&gt; nearly &lt;NUMBER&gt; million american slip middle class poverty                                                         | economy jobs new-hampshire-2012 poverty   |\n",
       "| 13 | 1 | mitt romney governor massachusetts didnt just slow rate growth government actually cut                                          | history state-budget                      |\n",
       "| 14 | 3 | economy bleed &lt;MONEY&gt; billion due government shutdown                                                                           | economy federal-budget health-care        |\n",
       "| 15 | 0 | affordable care act already sense waive otherwise suspend                                                                       | health-care                               |\n",
       "\n"
      ],
      "text/plain": [
       "   Labels\n",
       "1  1     \n",
       "2  2     \n",
       "3  3     \n",
       "4  1     \n",
       "5  2     \n",
       "6  5     \n",
       "7  0     \n",
       "8  2     \n",
       "9  2     \n",
       "10 3     \n",
       "11 3     \n",
       "12 2     \n",
       "13 1     \n",
       "14 3     \n",
       "15 0     \n",
       "   Text                                                                                                                           \n",
       "1  say annies list political group support <NUMBER> trimester abortion demand                                                     \n",
       "2  decline coal start start natural gas take start begin president george w bushs administration                                  \n",
       "3  hillary clinton agree john mccain vote give george bush benefit doubt iran                                                     \n",
       "4  health care reform legislation likely mandate free sex change surgery                                                          \n",
       "5  economic turnaround start end term                                                                                             \n",
       "6  chicago bear start quarterback last <NUMBER> year total numb tenure uw faculty fire last two decade                            \n",
       "7  jim dunnam live district represent year now                                                                                    \n",
       "8  be person stage work actively just last year pass along russ feingold tough ethic reform since watergate                       \n",
       "9  however take <MONEY> <NUMBER> million oregon lottery fund port newport eventually land new noaa marine operation center pacific\n",
       "10 say gop primary opponent glenn grothman joe leibham cast compromise vote cost <MONEY> million high electricity cost            \n",
       "11 first time history share national popular vote margin small latino vote margin                                                 \n",
       "12 since <YEAR> nearly <NUMBER> million american slip middle class poverty                                                        \n",
       "13 mitt romney governor massachusetts didnt just slow rate growth government actually cut                                         \n",
       "14 economy bleed <MONEY> billion due government shutdown                                                                          \n",
       "15 affordable care act already sense waive otherwise suspend                                                                      \n",
       "   Text_Tag                                 \n",
       "1  abortion                                 \n",
       "2  energy history job-accomplishments       \n",
       "3  foreign-policy                           \n",
       "4  health-care                              \n",
       "5  economy jobs                             \n",
       "6  education                                \n",
       "7  candidates-biography                     \n",
       "8  ethics                                   \n",
       "9  jobs                                     \n",
       "10 energy message-machine-2014 voting-record\n",
       "11 elections                                \n",
       "12 economy jobs new-hampshire-2012 poverty  \n",
       "13 history state-budget                     \n",
       "14 economy federal-budget health-care       \n",
       "15 health-care                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(train.df, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary <- get.unique.words(train.df$Text,sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary building \n",
    "\n",
    "#### We take part of the dataset (e.g. the first 80% of the records) and construct our vocabulary, which will be used for training. \n",
    "#### The remaining 20% will serve for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.df <- train.df[ceiling(0.8*nrow(train.df)):nrow(train.df),]\n",
    "train.df <- train.df[1:ceiling(0.8*nrow(train.df)),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocab.df, to store how many times each word appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "find.vocabulary <- function(N, unique=FALSE){\n",
    "    vocabulary.df <- data.frame(\"Token\" = vocabulary[1], \"Class_0\" = 0, \"Class_1\" = 0, \"Class_2\" = 0, \"Class_3\" = 0, \"Class_4\" = 0,\n",
    "                       \"Class_5\" = 0)\n",
    "    for (i in 1:N){\n",
    "        record <- train.df$Text[i]\n",
    "        class <- train.df$Labels[i]\n",
    "        temp.q <- str_split_1(plain(record), \" \")\n",
    "        if(unique){\n",
    "            temp.q <- unique(temp.q)\n",
    "        }\n",
    "        \n",
    "        for(word in temp.q){\n",
    "            if(!(word %in% vocabulary.df$Token)){\n",
    "                classes <- rep(0, 6)\n",
    "                classes[class + 1] <- 1\n",
    "                vocabulary.df <- rbind(vocabulary.df, list(word, classes[1], classes[2], \n",
    "                                                 classes[3], classes[4], classes[5], classes[6]))\n",
    "            }\n",
    "            else{\n",
    "                #Trova dove sta la parola --> somma 1 al contatore della classe\n",
    "                vocabulary.df[which(vocabulary.df$Token == word), class + 2] <- vocabulary.df[which(vocabulary.df$Token == word), class + 2] + 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return(vocabulary.df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "n.records <- length(train.df$Text) #Number of records\n",
    "vocab.df <- find.vocabulary(n.records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vocab.bool.df --> here we store in how many documents of each class the word appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.bool.df <- find.vocabulary(n.records, TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Token</th><th scope=col>Class_0</th><th scope=col>Class_1</th><th scope=col>Class_2</th><th scope=col>Class_3</th><th scope=col>Class_4</th><th scope=col>Class_5</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>say      </td><td>410</td><td>430</td><td>442</td><td>371</td><td>209</td><td>304</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>annies   </td><td>  0</td><td>  1</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>list     </td><td>  4</td><td>  2</td><td>  6</td><td>  5</td><td>  1</td><td>  5</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>political</td><td>  3</td><td> 12</td><td>  6</td><td>  8</td><td>  1</td><td>  9</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>group    </td><td> 13</td><td> 13</td><td>  6</td><td>  4</td><td> 11</td><td>  3</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>support  </td><td> 56</td><td> 52</td><td> 66</td><td> 42</td><td> 12</td><td> 32</td></tr>\n",
       "\t<tr><th scope=row>7</th><td>&lt;number&gt; </td><td>382</td><td>400</td><td>590</td><td>594</td><td>135</td><td>443</td></tr>\n",
       "\t<tr><th scope=row>8</th><td>trimester</td><td>  0</td><td>  2</td><td>  0</td><td>  0</td><td>  0</td><td>  0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Token & Class\\_0 & Class\\_1 & Class\\_2 & Class\\_3 & Class\\_4 & Class\\_5\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & say       & 410 & 430 & 442 & 371 & 209 & 304\\\\\n",
       "\t2 & annies    &   0 &   1 &   0 &   0 &   0 &   0\\\\\n",
       "\t3 & list      &   4 &   2 &   6 &   5 &   1 &   5\\\\\n",
       "\t4 & political &   3 &  12 &   6 &   8 &   1 &   9\\\\\n",
       "\t5 & group     &  13 &  13 &   6 &   4 &  11 &   3\\\\\n",
       "\t6 & support   &  56 &  52 &  66 &  42 &  12 &  32\\\\\n",
       "\t7 & <number>  & 382 & 400 & 590 & 594 & 135 & 443\\\\\n",
       "\t8 & trimester &   0 &   2 &   0 &   0 &   0 &   0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 7\n",
       "\n",
       "| <!--/--> | Token &lt;chr&gt; | Class_0 &lt;dbl&gt; | Class_1 &lt;dbl&gt; | Class_2 &lt;dbl&gt; | Class_3 &lt;dbl&gt; | Class_4 &lt;dbl&gt; | Class_5 &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | say       | 410 | 430 | 442 | 371 | 209 | 304 |\n",
       "| 2 | annies    |   0 |   1 |   0 |   0 |   0 |   0 |\n",
       "| 3 | list      |   4 |   2 |   6 |   5 |   1 |   5 |\n",
       "| 4 | political |   3 |  12 |   6 |   8 |   1 |   9 |\n",
       "| 5 | group     |  13 |  13 |   6 |   4 |  11 |   3 |\n",
       "| 6 | support   |  56 |  52 |  66 |  42 |  12 |  32 |\n",
       "| 7 | &lt;number&gt;  | 382 | 400 | 590 | 594 | 135 | 443 |\n",
       "| 8 | trimester |   0 |   2 |   0 |   0 |   0 |   0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Token     Class_0 Class_1 Class_2 Class_3 Class_4 Class_5\n",
       "1 say       410     430     442     371     209     304    \n",
       "2 annies      0       1       0       0       0       0    \n",
       "3 list        4       2       6       5       1       5    \n",
       "4 political   3      12       6       8       1       9    \n",
       "5 group      13      13       6       4      11       3    \n",
       "6 support    56      52      66      42      12      32    \n",
       "7 <number>  382     400     590     594     135     443    \n",
       "8 trimester   0       2       0       0       0       0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(vocab.bool.df, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "We must now perform feature selection: this means selecting a subset of the vocabulary and use that subset for classification.\n",
    "\n",
    "### $\\chi^2$ method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CHI2\n",
    "\n",
    "CHIs <- rep(0, length(vocab.bool.df$Token))                     #Vector with Chi^2 values\n",
    "NCs <- hist(train.df$Labels,breaks=seq(-1,5),plot=FALSE)$counts #Number of documents for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(i in 1:length(vocab.bool.df$Token)){\n",
    "    Chi <- 0\n",
    "    N.t <- sum(vocab.bool.df[i, 2:7])\n",
    "    N.nott <- n.records - N.t \n",
    "    for(class in 0:5){\n",
    "        N.c <- NCs[class + 1]\n",
    "        N.ct <- vocab.bool.df[i, class + 2]\n",
    "        E <- n.records * N.c/n.records * N.t/n.records\n",
    "        Chi <- Chi + (N.ct - E)^2 / E\n",
    "        \n",
    "        # N_c,nontoken - E_c, nontoken \n",
    "        N.c.nott <- N.c - N.ct\n",
    "        E <- n.records * N.c/n.records * N.nott/n.records\n",
    "        Chi <- Chi + (N.c.nott - E)^2 / E\n",
    "    }\n",
    "    \n",
    "    CHIs[i] <- Chi\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now CHIs contains the chi^2 for each token --> let's try ranking them\n",
    "vocab.df$Chi <- CHIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.bool.df$Chi <- CHIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 7794 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Token</th><th scope=col>Class_0</th><th scope=col>Class_1</th><th scope=col>Class_2</th><th scope=col>Class_3</th><th scope=col>Class_4</th><th scope=col>Class_5</th><th scope=col>Chi</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>7</th><td>&lt;number&gt; </td><td>553</td><td>609</td><td>974</td><td>938</td><td>204</td><td>729</td><td>106.61974</td></tr>\n",
       "\t<tr><th scope=row>732</th><td>socialist</td><td>  1</td><td>  1</td><td>  0</td><td>  0</td><td> 10</td><td>  1</td><td> 84.35517</td></tr>\n",
       "\t<tr><th scope=row>167</th><td>rep      </td><td> 25</td><td> 19</td><td> 16</td><td>  5</td><td> 30</td><td> 10</td><td> 77.77005</td></tr>\n",
       "\t<tr><th scope=row>150</th><td>percent  </td><td>121</td><td>115</td><td>228</td><td>233</td><td> 34</td><td>193</td><td> 62.54439</td></tr>\n",
       "\t<tr><th scope=row>1</th><td>say      </td><td>442</td><td>465</td><td>473</td><td>398</td><td>233</td><td>326</td><td> 43.91115</td></tr>\n",
       "\t<tr><th scope=row>79</th><td>since    </td><td> 30</td><td> 30</td><td> 74</td><td> 67</td><td> 14</td><td> 69</td><td> 40.23848</td></tr>\n",
       "\t<tr><th scope=row>263</th><td>obama    </td><td>106</td><td>130</td><td>131</td><td> 86</td><td> 76</td><td> 68</td><td> 39.15072</td></tr>\n",
       "\t<tr><th scope=row>2781</th><td>duffy    </td><td>  0</td><td>  1</td><td>  0</td><td>  0</td><td>  4</td><td>  0</td><td> 35.93560</td></tr>\n",
       "\t<tr><th scope=row>135</th><td>cut      </td><td> 68</td><td> 44</td><td> 99</td><td> 72</td><td> 12</td><td> 40</td><td> 35.71443</td></tr>\n",
       "\t<tr><th scope=row>1404</th><td>cup      </td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  3</td><td>  0</td><td> 34.40530</td></tr>\n",
       "\t<tr><th scope=row>1815</th><td>advisory </td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  3</td><td>  0</td><td> 34.40530</td></tr>\n",
       "\t<tr><th scope=row>2215</th><td>sic      </td><td>  0</td><td>  0</td><td>  0</td><td>  0</td><td>  3</td><td>  0</td><td> 34.40530</td></tr>\n",
       "\t<tr><th scope=row>368</th><td>obamacare</td><td> 43</td><td> 38</td><td> 33</td><td> 20</td><td> 22</td><td>  9</td><td> 33.24678</td></tr>\n",
       "\t<tr><th scope=row>400</th><td>country  </td><td> 36</td><td> 43</td><td> 75</td><td> 90</td><td> 17</td><td> 75</td><td> 32.48535</td></tr>\n",
       "\t<tr><th scope=row>632</th><td>average  </td><td> 20</td><td> 17</td><td> 46</td><td> 51</td><td>  3</td><td> 29</td><td> 31.74109</td></tr>\n",
       "\t<tr><th scope=row>413</th><td>half     </td><td> 12</td><td> 13</td><td> 21</td><td> 35</td><td>  2</td><td> 35</td><td> 31.23927</td></tr>\n",
       "\t<tr><th scope=row>374</th><td>barack   </td><td> 42</td><td> 70</td><td> 59</td><td> 38</td><td> 38</td><td> 27</td><td> 30.52295</td></tr>\n",
       "\t<tr><th scope=row>697</th><td>obamas   </td><td> 19</td><td> 23</td><td> 20</td><td> 10</td><td> 21</td><td>  9</td><td> 29.85357</td></tr>\n",
       "\t<tr><th scope=row>421</th><td>georgia  </td><td> 14</td><td> 10</td><td> 22</td><td> 29</td><td>  3</td><td> 37</td><td> 29.73327</td></tr>\n",
       "\t<tr><th scope=row>52</th><td>year     </td><td>159</td><td>155</td><td>230</td><td>230</td><td> 44</td><td>184</td><td> 29.70379</td></tr>\n",
       "\t<tr><th scope=row>107</th><td>high     </td><td> 50</td><td> 36</td><td> 78</td><td> 86</td><td>  9</td><td> 59</td><td> 29.36420</td></tr>\n",
       "\t<tr><th scope=row>2780</th><td>sean     </td><td>  1</td><td>  1</td><td>  0</td><td>  0</td><td>  4</td><td>  0</td><td> 29.15794</td></tr>\n",
       "\t<tr><th scope=row>3240</th><td>navy     </td><td>  0</td><td>  0</td><td>  1</td><td>  0</td><td>  5</td><td>  1</td><td> 29.07328</td></tr>\n",
       "\t<tr><th scope=row>35</th><td>care     </td><td> 85</td><td> 90</td><td> 85</td><td> 55</td><td> 49</td><td> 46</td><td> 27.64322</td></tr>\n",
       "\t<tr><th scope=row>2700</th><td>takeover </td><td>  2</td><td>  4</td><td>  0</td><td>  0</td><td>  5</td><td>  0</td><td> 27.11462</td></tr>\n",
       "\t<tr><th scope=row>202</th><td>state    </td><td>163</td><td>214</td><td>241</td><td>253</td><td> 55</td><td>219</td><td> 26.90833</td></tr>\n",
       "\t<tr><th scope=row>122</th><td>middle   </td><td> 23</td><td>  5</td><td> 15</td><td> 14</td><td>  9</td><td>  4</td><td> 26.82979</td></tr>\n",
       "\t<tr><th scope=row>2523</th><td>jeb      </td><td>  6</td><td>  1</td><td>  0</td><td> 12</td><td>  0</td><td>  2</td><td> 26.72409</td></tr>\n",
       "\t<tr><th scope=row>1052</th><td>t        </td><td> 15</td><td> 25</td><td>  9</td><td> 12</td><td>  7</td><td> 35</td><td> 26.61362</td></tr>\n",
       "\t<tr><th scope=row>1186</th><td>christmas</td><td>  2</td><td>  1</td><td>  2</td><td>  0</td><td>  5</td><td>  0</td><td> 26.13611</td></tr>\n",
       "\t<tr><th scope=row>⋮</th><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><th scope=row>616</th><td>beat       </td><td> 3</td><td> 2</td><td> 3</td><td> 3</td><td> 1</td><td> 2</td><td>0.8066555</td></tr>\n",
       "\t<tr><th scope=row>920</th><td>proposal   </td><td> 7</td><td> 9</td><td> 9</td><td> 7</td><td> 3</td><td> 9</td><td>0.7872832</td></tr>\n",
       "\t<tr><th scope=row>271</th><td>burn       </td><td> 1</td><td> 1</td><td> 2</td><td> 2</td><td> 1</td><td> 1</td><td>0.7708403</td></tr>\n",
       "\t<tr><th scope=row>2585</th><td>recommend  </td><td> 1</td><td> 1</td><td> 2</td><td> 1</td><td> 1</td><td> 1</td><td>0.7708403</td></tr>\n",
       "\t<tr><th scope=row>3311</th><td>broward    </td><td> 1</td><td> 2</td><td> 3</td><td> 1</td><td> 1</td><td> 2</td><td>0.7273499</td></tr>\n",
       "\t<tr><th scope=row>985</th><td>break      </td><td>12</td><td>14</td><td>15</td><td>14</td><td> 5</td><td> 9</td><td>0.7031000</td></tr>\n",
       "\t<tr><th scope=row>285</th><td>austin     </td><td> 8</td><td> 9</td><td> 8</td><td>10</td><td> 4</td><td>10</td><td>0.6551791</td></tr>\n",
       "\t<tr><th scope=row>1851</th><td>nowhere    </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td>0.6543247</td></tr>\n",
       "\t<tr><th scope=row>4217</th><td>effectively</td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td>0.6543247</td></tr>\n",
       "\t<tr><th scope=row>1817</th><td>park       </td><td> 4</td><td> 5</td><td> 4</td><td> 4</td><td> 1</td><td> 6</td><td>0.6355917</td></tr>\n",
       "\t<tr><th scope=row>3192</th><td>koch       </td><td> 2</td><td> 4</td><td> 3</td><td> 3</td><td> 1</td><td> 2</td><td>0.6021159</td></tr>\n",
       "\t<tr><th scope=row>353</th><td>require    </td><td>13</td><td>17</td><td>16</td><td>15</td><td> 6</td><td>13</td><td>0.5705722</td></tr>\n",
       "\t<tr><th scope=row>1413</th><td>unlimited  </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 0</td><td> 1</td><td>0.4920685</td></tr>\n",
       "\t<tr><th scope=row>2440</th><td>goldman    </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 0</td><td> 1</td><td>0.4920685</td></tr>\n",
       "\t<tr><th scope=row>2441</th><td>sachs      </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 0</td><td> 1</td><td>0.4920685</td></tr>\n",
       "\t<tr><th scope=row>3156</th><td>river      </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 0</td><td> 1</td><td>0.4920685</td></tr>\n",
       "\t<tr><th scope=row>3526</th><td>plot       </td><td> 1</td><td> 1</td><td> 1</td><td> 1</td><td> 0</td><td> 1</td><td>0.4920685</td></tr>\n",
       "\t<tr><th scope=row>1056</th><td>access     </td><td> 5</td><td> 6</td><td> 8</td><td> 7</td><td> 2</td><td> 5</td><td>0.4383785</td></tr>\n",
       "\t<tr><th scope=row>454</th><td>candidate  </td><td>20</td><td>22</td><td>25</td><td>24</td><td> 8</td><td>18</td><td>0.4381011</td></tr>\n",
       "\t<tr><th scope=row>688</th><td>always     </td><td> 3</td><td> 4</td><td> 3</td><td> 4</td><td> 1</td><td> 3</td><td>0.4375439</td></tr>\n",
       "\t<tr><th scope=row>1734</th><td>californias</td><td> 2</td><td> 2</td><td> 2</td><td> 2</td><td> 1</td><td> 1</td><td>0.4120316</td></tr>\n",
       "\t<tr><th scope=row>3183</th><td>plane      </td><td> 3</td><td> 2</td><td> 2</td><td> 2</td><td> 1</td><td> 1</td><td>0.4120316</td></tr>\n",
       "\t<tr><th scope=row>3872</th><td>activity   </td><td> 2</td><td> 2</td><td> 2</td><td> 2</td><td> 1</td><td> 1</td><td>0.4120316</td></tr>\n",
       "\t<tr><th scope=row>1932</th><td>hampshire  </td><td> 3</td><td> 4</td><td> 4</td><td> 5</td><td> 2</td><td> 4</td><td>0.3685609</td></tr>\n",
       "\t<tr><th scope=row>2859</th><td>qualify    </td><td> 2</td><td> 2</td><td> 2</td><td> 3</td><td> 1</td><td> 2</td><td>0.3516945</td></tr>\n",
       "\t<tr><th scope=row>436</th><td>long       </td><td>10</td><td>13</td><td>13</td><td>12</td><td> 6</td><td>11</td><td>0.3504499</td></tr>\n",
       "\t<tr><th scope=row>1254</th><td>female     </td><td> 2</td><td> 2</td><td> 3</td><td> 3</td><td> 1</td><td> 2</td><td>0.2563926</td></tr>\n",
       "\t<tr><th scope=row>1107</th><td>sheriff    </td><td> 2</td><td> 3</td><td> 3</td><td> 2</td><td> 1</td><td> 2</td><td>0.2400990</td></tr>\n",
       "\t<tr><th scope=row>659</th><td>gun        </td><td>24</td><td>30</td><td>37</td><td>30</td><td>13</td><td>28</td><td>0.2147557</td></tr>\n",
       "\t<tr><th scope=row>96</th><td>pacific    </td><td> 2</td><td> 3</td><td> 3</td><td> 3</td><td> 1</td><td> 2</td><td>0.1453119</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 7794 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & Token & Class\\_0 & Class\\_1 & Class\\_2 & Class\\_3 & Class\\_4 & Class\\_5 & Chi\\\\\n",
       "  & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t7 & <number>  & 553 & 609 & 974 & 938 & 204 & 729 & 106.61974\\\\\n",
       "\t732 & socialist &   1 &   1 &   0 &   0 &  10 &   1 &  84.35517\\\\\n",
       "\t167 & rep       &  25 &  19 &  16 &   5 &  30 &  10 &  77.77005\\\\\n",
       "\t150 & percent   & 121 & 115 & 228 & 233 &  34 & 193 &  62.54439\\\\\n",
       "\t1 & say       & 442 & 465 & 473 & 398 & 233 & 326 &  43.91115\\\\\n",
       "\t79 & since     &  30 &  30 &  74 &  67 &  14 &  69 &  40.23848\\\\\n",
       "\t263 & obama     & 106 & 130 & 131 &  86 &  76 &  68 &  39.15072\\\\\n",
       "\t2781 & duffy     &   0 &   1 &   0 &   0 &   4 &   0 &  35.93560\\\\\n",
       "\t135 & cut       &  68 &  44 &  99 &  72 &  12 &  40 &  35.71443\\\\\n",
       "\t1404 & cup       &   0 &   0 &   0 &   0 &   3 &   0 &  34.40530\\\\\n",
       "\t1815 & advisory  &   0 &   0 &   0 &   0 &   3 &   0 &  34.40530\\\\\n",
       "\t2215 & sic       &   0 &   0 &   0 &   0 &   3 &   0 &  34.40530\\\\\n",
       "\t368 & obamacare &  43 &  38 &  33 &  20 &  22 &   9 &  33.24678\\\\\n",
       "\t400 & country   &  36 &  43 &  75 &  90 &  17 &  75 &  32.48535\\\\\n",
       "\t632 & average   &  20 &  17 &  46 &  51 &   3 &  29 &  31.74109\\\\\n",
       "\t413 & half      &  12 &  13 &  21 &  35 &   2 &  35 &  31.23927\\\\\n",
       "\t374 & barack    &  42 &  70 &  59 &  38 &  38 &  27 &  30.52295\\\\\n",
       "\t697 & obamas    &  19 &  23 &  20 &  10 &  21 &   9 &  29.85357\\\\\n",
       "\t421 & georgia   &  14 &  10 &  22 &  29 &   3 &  37 &  29.73327\\\\\n",
       "\t52 & year      & 159 & 155 & 230 & 230 &  44 & 184 &  29.70379\\\\\n",
       "\t107 & high      &  50 &  36 &  78 &  86 &   9 &  59 &  29.36420\\\\\n",
       "\t2780 & sean      &   1 &   1 &   0 &   0 &   4 &   0 &  29.15794\\\\\n",
       "\t3240 & navy      &   0 &   0 &   1 &   0 &   5 &   1 &  29.07328\\\\\n",
       "\t35 & care      &  85 &  90 &  85 &  55 &  49 &  46 &  27.64322\\\\\n",
       "\t2700 & takeover  &   2 &   4 &   0 &   0 &   5 &   0 &  27.11462\\\\\n",
       "\t202 & state     & 163 & 214 & 241 & 253 &  55 & 219 &  26.90833\\\\\n",
       "\t122 & middle    &  23 &   5 &  15 &  14 &   9 &   4 &  26.82979\\\\\n",
       "\t2523 & jeb       &   6 &   1 &   0 &  12 &   0 &   2 &  26.72409\\\\\n",
       "\t1052 & t         &  15 &  25 &   9 &  12 &   7 &  35 &  26.61362\\\\\n",
       "\t1186 & christmas &   2 &   1 &   2 &   0 &   5 &   0 &  26.13611\\\\\n",
       "\t⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t616 & beat        &  3 &  2 &  3 &  3 &  1 &  2 & 0.8066555\\\\\n",
       "\t920 & proposal    &  7 &  9 &  9 &  7 &  3 &  9 & 0.7872832\\\\\n",
       "\t271 & burn        &  1 &  1 &  2 &  2 &  1 &  1 & 0.7708403\\\\\n",
       "\t2585 & recommend   &  1 &  1 &  2 &  1 &  1 &  1 & 0.7708403\\\\\n",
       "\t3311 & broward     &  1 &  2 &  3 &  1 &  1 &  2 & 0.7273499\\\\\n",
       "\t985 & break       & 12 & 14 & 15 & 14 &  5 &  9 & 0.7031000\\\\\n",
       "\t285 & austin      &  8 &  9 &  8 & 10 &  4 & 10 & 0.6551791\\\\\n",
       "\t1851 & nowhere     &  1 &  1 &  1 &  1 &  1 &  1 & 0.6543247\\\\\n",
       "\t4217 & effectively &  1 &  1 &  1 &  1 &  1 &  1 & 0.6543247\\\\\n",
       "\t1817 & park        &  4 &  5 &  4 &  4 &  1 &  6 & 0.6355917\\\\\n",
       "\t3192 & koch        &  2 &  4 &  3 &  3 &  1 &  2 & 0.6021159\\\\\n",
       "\t353 & require     & 13 & 17 & 16 & 15 &  6 & 13 & 0.5705722\\\\\n",
       "\t1413 & unlimited   &  1 &  1 &  1 &  1 &  0 &  1 & 0.4920685\\\\\n",
       "\t2440 & goldman     &  1 &  1 &  1 &  1 &  0 &  1 & 0.4920685\\\\\n",
       "\t2441 & sachs       &  1 &  1 &  1 &  1 &  0 &  1 & 0.4920685\\\\\n",
       "\t3156 & river       &  1 &  1 &  1 &  1 &  0 &  1 & 0.4920685\\\\\n",
       "\t3526 & plot        &  1 &  1 &  1 &  1 &  0 &  1 & 0.4920685\\\\\n",
       "\t1056 & access      &  5 &  6 &  8 &  7 &  2 &  5 & 0.4383785\\\\\n",
       "\t454 & candidate   & 20 & 22 & 25 & 24 &  8 & 18 & 0.4381011\\\\\n",
       "\t688 & always      &  3 &  4 &  3 &  4 &  1 &  3 & 0.4375439\\\\\n",
       "\t1734 & californias &  2 &  2 &  2 &  2 &  1 &  1 & 0.4120316\\\\\n",
       "\t3183 & plane       &  3 &  2 &  2 &  2 &  1 &  1 & 0.4120316\\\\\n",
       "\t3872 & activity    &  2 &  2 &  2 &  2 &  1 &  1 & 0.4120316\\\\\n",
       "\t1932 & hampshire   &  3 &  4 &  4 &  5 &  2 &  4 & 0.3685609\\\\\n",
       "\t2859 & qualify     &  2 &  2 &  2 &  3 &  1 &  2 & 0.3516945\\\\\n",
       "\t436 & long        & 10 & 13 & 13 & 12 &  6 & 11 & 0.3504499\\\\\n",
       "\t1254 & female      &  2 &  2 &  3 &  3 &  1 &  2 & 0.2563926\\\\\n",
       "\t1107 & sheriff     &  2 &  3 &  3 &  2 &  1 &  2 & 0.2400990\\\\\n",
       "\t659 & gun         & 24 & 30 & 37 & 30 & 13 & 28 & 0.2147557\\\\\n",
       "\t96 & pacific     &  2 &  3 &  3 &  3 &  1 &  2 & 0.1453119\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 7794 × 8\n",
       "\n",
       "| <!--/--> | Token &lt;chr&gt; | Class_0 &lt;dbl&gt; | Class_1 &lt;dbl&gt; | Class_2 &lt;dbl&gt; | Class_3 &lt;dbl&gt; | Class_4 &lt;dbl&gt; | Class_5 &lt;dbl&gt; | Chi &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 7 | &lt;number&gt;  | 553 | 609 | 974 | 938 | 204 | 729 | 106.61974 |\n",
       "| 732 | socialist |   1 |   1 |   0 |   0 |  10 |   1 |  84.35517 |\n",
       "| 167 | rep       |  25 |  19 |  16 |   5 |  30 |  10 |  77.77005 |\n",
       "| 150 | percent   | 121 | 115 | 228 | 233 |  34 | 193 |  62.54439 |\n",
       "| 1 | say       | 442 | 465 | 473 | 398 | 233 | 326 |  43.91115 |\n",
       "| 79 | since     |  30 |  30 |  74 |  67 |  14 |  69 |  40.23848 |\n",
       "| 263 | obama     | 106 | 130 | 131 |  86 |  76 |  68 |  39.15072 |\n",
       "| 2781 | duffy     |   0 |   1 |   0 |   0 |   4 |   0 |  35.93560 |\n",
       "| 135 | cut       |  68 |  44 |  99 |  72 |  12 |  40 |  35.71443 |\n",
       "| 1404 | cup       |   0 |   0 |   0 |   0 |   3 |   0 |  34.40530 |\n",
       "| 1815 | advisory  |   0 |   0 |   0 |   0 |   3 |   0 |  34.40530 |\n",
       "| 2215 | sic       |   0 |   0 |   0 |   0 |   3 |   0 |  34.40530 |\n",
       "| 368 | obamacare |  43 |  38 |  33 |  20 |  22 |   9 |  33.24678 |\n",
       "| 400 | country   |  36 |  43 |  75 |  90 |  17 |  75 |  32.48535 |\n",
       "| 632 | average   |  20 |  17 |  46 |  51 |   3 |  29 |  31.74109 |\n",
       "| 413 | half      |  12 |  13 |  21 |  35 |   2 |  35 |  31.23927 |\n",
       "| 374 | barack    |  42 |  70 |  59 |  38 |  38 |  27 |  30.52295 |\n",
       "| 697 | obamas    |  19 |  23 |  20 |  10 |  21 |   9 |  29.85357 |\n",
       "| 421 | georgia   |  14 |  10 |  22 |  29 |   3 |  37 |  29.73327 |\n",
       "| 52 | year      | 159 | 155 | 230 | 230 |  44 | 184 |  29.70379 |\n",
       "| 107 | high      |  50 |  36 |  78 |  86 |   9 |  59 |  29.36420 |\n",
       "| 2780 | sean      |   1 |   1 |   0 |   0 |   4 |   0 |  29.15794 |\n",
       "| 3240 | navy      |   0 |   0 |   1 |   0 |   5 |   1 |  29.07328 |\n",
       "| 35 | care      |  85 |  90 |  85 |  55 |  49 |  46 |  27.64322 |\n",
       "| 2700 | takeover  |   2 |   4 |   0 |   0 |   5 |   0 |  27.11462 |\n",
       "| 202 | state     | 163 | 214 | 241 | 253 |  55 | 219 |  26.90833 |\n",
       "| 122 | middle    |  23 |   5 |  15 |  14 |   9 |   4 |  26.82979 |\n",
       "| 2523 | jeb       |   6 |   1 |   0 |  12 |   0 |   2 |  26.72409 |\n",
       "| 1052 | t         |  15 |  25 |   9 |  12 |   7 |  35 |  26.61362 |\n",
       "| 1186 | christmas |   2 |   1 |   2 |   0 |   5 |   0 |  26.13611 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 616 | beat        |  3 |  2 |  3 |  3 |  1 |  2 | 0.8066555 |\n",
       "| 920 | proposal    |  7 |  9 |  9 |  7 |  3 |  9 | 0.7872832 |\n",
       "| 271 | burn        |  1 |  1 |  2 |  2 |  1 |  1 | 0.7708403 |\n",
       "| 2585 | recommend   |  1 |  1 |  2 |  1 |  1 |  1 | 0.7708403 |\n",
       "| 3311 | broward     |  1 |  2 |  3 |  1 |  1 |  2 | 0.7273499 |\n",
       "| 985 | break       | 12 | 14 | 15 | 14 |  5 |  9 | 0.7031000 |\n",
       "| 285 | austin      |  8 |  9 |  8 | 10 |  4 | 10 | 0.6551791 |\n",
       "| 1851 | nowhere     |  1 |  1 |  1 |  1 |  1 |  1 | 0.6543247 |\n",
       "| 4217 | effectively |  1 |  1 |  1 |  1 |  1 |  1 | 0.6543247 |\n",
       "| 1817 | park        |  4 |  5 |  4 |  4 |  1 |  6 | 0.6355917 |\n",
       "| 3192 | koch        |  2 |  4 |  3 |  3 |  1 |  2 | 0.6021159 |\n",
       "| 353 | require     | 13 | 17 | 16 | 15 |  6 | 13 | 0.5705722 |\n",
       "| 1413 | unlimited   |  1 |  1 |  1 |  1 |  0 |  1 | 0.4920685 |\n",
       "| 2440 | goldman     |  1 |  1 |  1 |  1 |  0 |  1 | 0.4920685 |\n",
       "| 2441 | sachs       |  1 |  1 |  1 |  1 |  0 |  1 | 0.4920685 |\n",
       "| 3156 | river       |  1 |  1 |  1 |  1 |  0 |  1 | 0.4920685 |\n",
       "| 3526 | plot        |  1 |  1 |  1 |  1 |  0 |  1 | 0.4920685 |\n",
       "| 1056 | access      |  5 |  6 |  8 |  7 |  2 |  5 | 0.4383785 |\n",
       "| 454 | candidate   | 20 | 22 | 25 | 24 |  8 | 18 | 0.4381011 |\n",
       "| 688 | always      |  3 |  4 |  3 |  4 |  1 |  3 | 0.4375439 |\n",
       "| 1734 | californias |  2 |  2 |  2 |  2 |  1 |  1 | 0.4120316 |\n",
       "| 3183 | plane       |  3 |  2 |  2 |  2 |  1 |  1 | 0.4120316 |\n",
       "| 3872 | activity    |  2 |  2 |  2 |  2 |  1 |  1 | 0.4120316 |\n",
       "| 1932 | hampshire   |  3 |  4 |  4 |  5 |  2 |  4 | 0.3685609 |\n",
       "| 2859 | qualify     |  2 |  2 |  2 |  3 |  1 |  2 | 0.3516945 |\n",
       "| 436 | long        | 10 | 13 | 13 | 12 |  6 | 11 | 0.3504499 |\n",
       "| 1254 | female      |  2 |  2 |  3 |  3 |  1 |  2 | 0.2563926 |\n",
       "| 1107 | sheriff     |  2 |  3 |  3 |  2 |  1 |  2 | 0.2400990 |\n",
       "| 659 | gun         | 24 | 30 | 37 | 30 | 13 | 28 | 0.2147557 |\n",
       "| 96 | pacific     |  2 |  3 |  3 |  3 |  1 |  2 | 0.1453119 |\n",
       "\n"
      ],
      "text/plain": [
       "     Token       Class_0 Class_1 Class_2 Class_3 Class_4 Class_5 Chi      \n",
       "7    <number>    553     609     974     938     204     729     106.61974\n",
       "732  socialist     1       1       0       0      10       1      84.35517\n",
       "167  rep          25      19      16       5      30      10      77.77005\n",
       "150  percent     121     115     228     233      34     193      62.54439\n",
       "1    say         442     465     473     398     233     326      43.91115\n",
       "79   since        30      30      74      67      14      69      40.23848\n",
       "263  obama       106     130     131      86      76      68      39.15072\n",
       "2781 duffy         0       1       0       0       4       0      35.93560\n",
       "135  cut          68      44      99      72      12      40      35.71443\n",
       "1404 cup           0       0       0       0       3       0      34.40530\n",
       "1815 advisory      0       0       0       0       3       0      34.40530\n",
       "2215 sic           0       0       0       0       3       0      34.40530\n",
       "368  obamacare    43      38      33      20      22       9      33.24678\n",
       "400  country      36      43      75      90      17      75      32.48535\n",
       "632  average      20      17      46      51       3      29      31.74109\n",
       "413  half         12      13      21      35       2      35      31.23927\n",
       "374  barack       42      70      59      38      38      27      30.52295\n",
       "697  obamas       19      23      20      10      21       9      29.85357\n",
       "421  georgia      14      10      22      29       3      37      29.73327\n",
       "52   year        159     155     230     230      44     184      29.70379\n",
       "107  high         50      36      78      86       9      59      29.36420\n",
       "2780 sean          1       1       0       0       4       0      29.15794\n",
       "3240 navy          0       0       1       0       5       1      29.07328\n",
       "35   care         85      90      85      55      49      46      27.64322\n",
       "2700 takeover      2       4       0       0       5       0      27.11462\n",
       "202  state       163     214     241     253      55     219      26.90833\n",
       "122  middle       23       5      15      14       9       4      26.82979\n",
       "2523 jeb           6       1       0      12       0       2      26.72409\n",
       "1052 t            15      25       9      12       7      35      26.61362\n",
       "1186 christmas     2       1       2       0       5       0      26.13611\n",
       "⋮    ⋮           ⋮       ⋮       ⋮       ⋮       ⋮       ⋮       ⋮        \n",
       "616  beat         3       2       3       3       1       2      0.8066555\n",
       "920  proposal     7       9       9       7       3       9      0.7872832\n",
       "271  burn         1       1       2       2       1       1      0.7708403\n",
       "2585 recommend    1       1       2       1       1       1      0.7708403\n",
       "3311 broward      1       2       3       1       1       2      0.7273499\n",
       "985  break       12      14      15      14       5       9      0.7031000\n",
       "285  austin       8       9       8      10       4      10      0.6551791\n",
       "1851 nowhere      1       1       1       1       1       1      0.6543247\n",
       "4217 effectively  1       1       1       1       1       1      0.6543247\n",
       "1817 park         4       5       4       4       1       6      0.6355917\n",
       "3192 koch         2       4       3       3       1       2      0.6021159\n",
       "353  require     13      17      16      15       6      13      0.5705722\n",
       "1413 unlimited    1       1       1       1       0       1      0.4920685\n",
       "2440 goldman      1       1       1       1       0       1      0.4920685\n",
       "2441 sachs        1       1       1       1       0       1      0.4920685\n",
       "3156 river        1       1       1       1       0       1      0.4920685\n",
       "3526 plot         1       1       1       1       0       1      0.4920685\n",
       "1056 access       5       6       8       7       2       5      0.4383785\n",
       "454  candidate   20      22      25      24       8      18      0.4381011\n",
       "688  always       3       4       3       4       1       3      0.4375439\n",
       "1734 californias  2       2       2       2       1       1      0.4120316\n",
       "3183 plane        3       2       2       2       1       1      0.4120316\n",
       "3872 activity     2       2       2       2       1       1      0.4120316\n",
       "1932 hampshire    3       4       4       5       2       4      0.3685609\n",
       "2859 qualify      2       2       2       3       1       2      0.3516945\n",
       "436  long        10      13      13      12       6      11      0.3504499\n",
       "1254 female       2       2       3       3       1       2      0.2563926\n",
       "1107 sheriff      2       3       3       2       1       2      0.2400990\n",
       "659  gun         24      30      37      30      13      28      0.2147557\n",
       "96   pacific      2       3       3       3       1       2      0.1453119"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab.df[order(vocab.df$Chi, decreasing = TRUE),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really like that the $\\chi^2$ method seems to like terms which appear only in one class. This can be misguiding, so let's try with the Mutual Information.\n",
    "\n",
    "## Mutual Information \n",
    "We evaluate the mutual information for each class (among the possibilities (class, not class)) and make an average.\n",
    "\n",
    "$\\sum_{\\mathrm{class}\\in\\{0,1\\}}\\sum_{\\mathrm{token}\\in\\{0,1\\}}P(class, token) \\log{\\frac{P(class, token)}{P(class)P(token)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num [1:7794] 0 0 0 0 0 0 0 0 0 0 ...\n"
     ]
    }
   ],
   "source": [
    "MIs <- rep(0, length(vocab.bool.df$Token))\n",
    "cat(str(MIs))\n",
    "\n",
    "#Evaluate MI separately for each class, then average\n",
    "for(i in 1:length(vocab.df$Token)){\n",
    "    MI <- 0\n",
    "    N.t <- sum(vocab.bool.df[i, 2:7])\n",
    "    N.not.t <- n.records - N.t\n",
    "    for(class in 0:5){\n",
    "        MI.c <- 0\n",
    "        N.c <- NCs[class + 1]\n",
    "        N.not.c <- n.records - N.c \n",
    "        N.ct <- vocab.bool.df[i, class + 2]\n",
    "        \n",
    "        class.index <- switch(class + 1, \"Class_0\", \"Class_1\", \"Class_2\", \"Class_3\", \"Class_4\", \"Class_5\")\n",
    "        N.not.c.not.t <- n.records - sum(vocab.bool.df[i, 2:7]) + N.ct - sum(vocab.bool.df$class.index)\n",
    "        \n",
    "        \n",
    "        #P(class, token)log(...) + P(nonclass, token) + P(class, non token) + P(non class, non token)\n",
    "        term <- ifelse(N.ct > 0, N.ct/n.records*log(N.ct*n.records/(N.c*N.t)), 0) + \n",
    "                ifelse((N.t - N.ct) > 0, (N.t - N.ct)/n.records*log((N.t-N.ct)*n.records/(N.not.c*N.t)), 0)+\n",
    "                ifelse((N.c - N.ct) > 0, (N.c - N.ct)/n.records*log((N.c - N.ct)*n.records/(N.c * (N.not.t))), 0) + \n",
    "                ifelse(N.not.c.not.t > 0, N.not.c.not.t/n.records * log(N.not.c.not.t*n.records / (N.not.c * N.not.t)), 0)\n",
    "                \n",
    "        MI <- MI + term\n",
    "        \n",
    "    }\n",
    "    \n",
    "    MIs[i] <- MI\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.df$MI <- MIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.df.order.MI <- vocab.df[order(vocab.df$MI, decreasing = TRUE), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation\n",
    "\n",
    "We compute the parameters of our MNB, using different numbers of features. We train it on different vocabulary sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "7794"
      ],
      "text/latex": [
       "7794"
      ],
      "text/markdown": [
       "7794"
      ],
      "text/plain": [
       "[1] 7794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(vocab.df$Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.sizes <- seq(from = 50, to = 7050, by = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score for different vocabulary sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores <- rep(0, length(vocab.sizes))\n",
    "\n",
    "for(score.index in 1:length(vocab.sizes)){\n",
    "    size <- vocab.sizes[score.index]\n",
    "    vocab.short <- vocab.df.order.MI[1:size, ]\n",
    "    \n",
    "    #Prior\n",
    "    p.c <- log(NCs / n.records)\n",
    "\n",
    "    posteriors.df <- vocab.short\n",
    "\n",
    "    for(class in 0:5){\n",
    "        posteriors.df[, class + 2] <- log(posteriors.df[, class + 2] / sum(posteriors.df[, class + 2]))\n",
    "    } \n",
    "    \n",
    "    predictions <- rep(0, length(validation.df$Text))\n",
    "    for(i in 1:length(validation.df$Text)){\n",
    "        record <- validation.df$Text[i]\n",
    "        words <- str_split_1(plain(record), \" \") \n",
    "        posteriors <- rep(0, 6) #Posterior probabilities (we want to find the maximum)\n",
    "        for(class in 0:5){\n",
    "            #For each class evaluate posterior\n",
    "            posterior <- p.c[class + 1]\n",
    "            for(word in words){\n",
    "                #Check if word in vocabulary\n",
    "                if(word %in% posteriors.df$Token){\n",
    "                    posterior <- posterior + posteriors.df[which(posteriors.df$Token == word) , class + 2]\n",
    "                }\n",
    "            }\n",
    "            posteriors[class + 1] <- posterior\n",
    "        }\n",
    "\n",
    "        predictions[i] <- which.max(posteriors) - 1\n",
    "    }\n",
    "    \n",
    "    scores[score.index] <- sum(predictions == validation.df$Labels) / length(validation.df$Labels)\n",
    "    \n",
    "}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.results <- data.frame(vocab.sizes, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>vocab.sizes</th><th scope=col>scores</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>6</th><td>550</td><td>0.237793</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & vocab.sizes & scores\\\\\n",
       "  & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t6 & 550 & 0.237793\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 2\n",
       "\n",
       "| <!--/--> | vocab.sizes &lt;dbl&gt; | scores &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 6 | 550 | 0.237793 |\n",
       "\n"
      ],
      "text/plain": [
       "  vocab.sizes scores  \n",
       "6 550         0.237793"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores.results[which.max(scores.results$scores),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix\n",
    "We want to plot the confusion matrices, just to check what it is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    " - Sistemare ordine classi "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
